---
---
References
==========

@misc{Gomez2018,
author = {G{\'{o}}mez, Ra{\'{u}}l},
month = {may},
title = {{Understanding Categorical Cross-Entropy Loss, Binary Cross-Entropy Loss, Softmax Loss, Logistic Loss, Focal Loss and all those confusing names}},
url = {https://gombru.github.io/2018/05/23/cross{\_}entropy{\_}loss/},
urldate = {2020-12-22},
year = {2018}
}

@book{Bray2015,
author = {Bray, Adam and Horton, Cole and Kogge, Michael and Dougherty, Kerrie},
pages = {200},
publisher = {DK Children},
title = {{Star Wars: Absolutely Everything You Need to Know}},
year = {2015}
}

@article{Brown2020,
archivePrefix = {arXiv},
arxivId = {2005.14165},
author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
eprint = {2005.14165},
month = {may},
title = {{Language Models are Few-Shot Learners}},
url = {https://arxiv.org/abs/2005.14165},
year = {2020}
}

@book{Neil2012,
abstract = {Anterior cruciate ligament tears, common among athletes, are functionally disabling; they predispose the knee to subsequent injuries and the early onset of osteoarthritis. A total of 3810 studies published between January 1994 and the present were identified and reviewed to determine the current state of knowledge regarding the treatment of anterior cruciate ligament injuries. Part 1 of this article focused on studies pertaining to the biomechanical behavior of the anterior cruciate ligament, the prevalence of and risk factors for injuries related to it, the natural history of the ligament-deficient knee, injuries associated with anterior cruciate ligament disruption, indications for the treatment of anterior cruciate ligament injuries, as well as nonoperative and operative treatments. Part 2 includes technical aspects of anterior cruciate ligament surgery, bone tunnel widening, graft healing, rehabilitation after anterior cruciate ligament reconstruction, and the effects of sex, age, and activity level on the outcome of such reconstructive surgery.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Neil, Carlson},
booktitle = {IEEE Transactions on Information Theory},
eprint = {arXiv:1011.1669v3},
isbn = {9781118018491},
issn = {0363-5465},
keywords = {ormal child psychology},
pmid = {16230470},
title = {{Physiology of Behavior}},
year = {2012}
}

@inproceedings{Krizhevsky2012,
abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5{\%} and 17.0{\%} which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully-connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully-connected layers we employed a recently-developed regularization method called "dropout" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3{\%}, compared to 26.2{\%} achieved by the second-best entry.},
author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
booktitle = {Advances in Neural Information Processing Systems},
doi = {10.1061/(ASCE)GT.1943-5606.0001284},
isbn = {9781627480031},
issn = {10495258},
title = {{ImageNet classification with deep convolutional neural networks}},
year = {2012}
}

@inproceedings{He2016,
abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8× deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57{\%} error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28{\%} relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC {\&} COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
archivePrefix = {arXiv},
arxivId = {1512.03385},
author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2016.90},
eprint = {1512.03385},
isbn = {9781467388504},
issn = {10636919},
title = {{Deep residual learning for image recognition}},
year = {2016}
}

@article{Gatys2015,
abstract = {In fine art, especially painting, humans have mastered the skill to create unique visual experiences through composing a complex interplay between the content and style of an image. Thus far the algorithmic basis of this process is unknown and there exists no artificial system with similar capabilities. However, in other key areas of visual perception such as object and face recognition near-human performance was recently demonstrated by a class of biologically inspired vision models called Deep Neural Networks. Here we introduce an artificial system based on a Deep Neural Network that creates artistic images of high perceptual quality. The system uses neural representations to separate and recombine content and style of arbitrary images, providing a neural algorithm for the creation of artistic images. Moreover, in light of the striking similarities between performance-optimised artificial neural networks and biological vision, our work offers a path forward to an algorithmic understanding of how humans create and perceive artistic imagery.},
archivePrefix = {arXiv},
arxivId = {1508.06576},
author = {Gatys, Leon and Ecker, Alexander and Bethge, Matthias},
doi = {10.1167/16.12.326},
eprint = {1508.06576},
issn = {1534-7362},
journal = {Journal of Vision},
title = {{A Neural Algorithm of Artistic Style}},
year = {2015}
}
@article{Shannon1948,
author = {Shannon, C. E.},
doi = {10.1002/j.1538-7305.1948.tb01338.x},
issn = {15387305},
journal = {Bell System Technical Journal},
title = {{A Mathematical Theory of Communication}},
year = {1948}
}

@misc{Cs231n,
author = {Stanford, Cs231n},
title = {{CS231n Convolutional Neural Networks for Visual Recognition}},
url = {https://cs231n.github.io/convolutional-networks/},
urldate = {2020-12-21}
}

@misc{DotCSV2020,
abstract = {Una Red Neuronal Convolucional es un tipo de red capaz de observar los patrones m{\'{a}}s complejos de una imagen. ¿Sabes c{\'{o}}mo funcionan? ¡Te lo explico!},
author = {{Dot CSV}},
title = {{¿Qu{\'{e}} es una Red Neuronal Convolucional? Los OJOS de la Inteligencia Artificial - YouTube}},
url = {https://www.youtube.com/watch?v=V8j1oENVz00},
urldate = {2020-12-19},
year = {2020}
}
