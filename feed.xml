<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://www.javiergamazo.com//blog/feed.xml" rel="self" type="application/atom+xml" /><link href="https://www.javiergamazo.com//blog/" rel="alternate" type="text/html" /><updated>2020-12-17T22:14:51+00:00</updated><id>https://www.javiergamazo.com//blog/feed.xml</id><title type="html">DidYouKnow</title><subtitle>The place where I talk about anything</subtitle><entry><title type="html">¿Puede una IA inventar un idioma?</title><link href="https://www.javiergamazo.com//blog/jekyll/update/2020/11/07/es_draft.html" rel="alternate" type="text/html" title="¿Puede una IA inventar un idioma?" /><published>2020-11-07T18:39:02+00:00</published><updated>2020-11-07T18:39:02+00:00</updated><id>https://www.javiergamazo.com//blog/jekyll/update/2020/11/07/es_draft</id><content type="html" xml:base="https://www.javiergamazo.com//blog/jekyll/update/2020/11/07/es_draft.html">&lt;p&gt;La pregunta que encabeza este post es recurrente en todos los círculos de la Inteligencia Artificial. Aquellos que trabajan en NLP (procesamiento de lenguaje natural por sus siglas en inglés) buscan concebir sistemas que sean capaces de entender (procesar) lenguaje producido por seres humanos y tomar acciones acordes. GPT-3 es un ejemplo de esto, el cometido de este modelo tan solo es predecir (muy acertadamente) la palabra más probable que seguirá una secuencia de texto (missing reference). Sin embargo, según cómo ha sido entrenado, en ningún caso se puede defender que el modelo posea una comprensión profunda de las palabras que está produciendo ni que tenga un objetivo en particular al expresarlas. Si se me permite mi opinión, creo que el salto que nos queda por delante hasta cubrir este último punto es todavía enorme y no vendrá en los próximos años. Al fin y al cabo, todavía no entendemos cómo funciona la mente humana.&lt;/p&gt;

&lt;p&gt;Si atendemos a la definición de “idioma” en el Diccionario, ésta es “Lengua de un pueblo o nación, o común a varios” (missing reference), mientras que una de las acepciones de “lengua” es “Sistema de comunicación verbal propio de una comunidad humana y que cuenta generalmente con escritura” (missing reference). Cuando hablemos de “idioma” en este post, por lo tanto, nos estaremos refiriendo a un lenguaje común que compartan varios sistemas a través del cual puedan llegar a entenderse y transmitir ideas. No obstante, estas ideas vendrán predefinidas por un agente externo a la IA. Un ejemplo básico podría ser transmitir un número aleatorio del sistema A al B en un lenguaje común, que el B lo procesara, calculara su doble, lo devolviera a A y éste diera con la respuesta correcta. En este post intentaremos sentar las bases de un proyecto que cumpla todos esos requisitos y una condición más: que el idioma que compartan ambos sistemas sea similar al del droide R2-D2 de Star Wars.&lt;/p&gt;

&lt;h3 id=&quot;dos-no-hablan-si-uno-no-quiere&quot;&gt;Dos no hablan si uno no quiere&lt;/h3&gt;

&lt;p&gt;Efectivamente, para que exista comunicación debe haber al menos dos sistemas: un emisor de información (transmisor) y otro receptor de la misma. Siguiendo la Teoría de la Comunicación de Claude E. Shannon (missing reference), es necesario además una fuente de información, un canal, un mensaje, un destinatario y un elemento de ruido. Si bien la definición precisa de estos componentes se deja a discreción del lector, es de capital importancia para este proyecto distinguir entre &lt;span style=&quot;color:blue&quot;&gt;fuente de información&lt;/span&gt; y &lt;span style=&quot;color:red&quot;&gt;transmisor&lt;/span&gt;, y &lt;span style=&quot;color:blue&quot;&gt;destinatario&lt;/span&gt; y &lt;span style=&quot;color:red&quot;&gt;receptor&lt;/span&gt;: cuando hablamos de transmisor nos referimos al sistema técnico encargado de &lt;em&gt;codificar&lt;/em&gt; la fuente de información a un conjunto de señales aptas para el canal (y viceversa para el receptor, que la &lt;em&gt;decodifica&lt;/em&gt; para que el destinatario pueda utilizar la información). Aplicado a la comunicación verbal entre dos personas A y B, la fuente de información será la idea de A, cuyo cerebro se encargará de codificar en forma de palabras (mensaje) que se enviarán por el aire (canal) hasta llegar a B. El cerebro de B decodificará las palabras y generará una idea, que en el mejor de los casos será igual a la idea del cerebro de A.
&lt;!-- Habría que poner una foto aquí de la teoría de información --&gt;&lt;/p&gt;

&lt;p&gt;Transformemos ahora esta teoría al campo de la IA. Como sabemos, las redes neuronales son tremendamente eficaces a la hora de generar representaciones a partir de datos, por lo que podríamos enfrentar dos de ellas (sujetos A y B) y hacerlas compartir mensajes. A codificaría el mensaje y B lo… ¿decodificaría? ¿Y qué pasaría si B quisiera transmitir una idea a A? Para encontrar la solución a esta pregunta podemos fijarnos en el sistema más eficiente que conocemos a la hora de producir y procesar lenguaje: el cerebro. Este órgano se encarga de ambas funciones simultáneamente (¿o es que no puedes escuchar música y hablar a la vez?), y eso se debe a que el flujo de información transcurre por zonas separadas&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;. Estas dos zonas son el área de Wernicke y el área de Broca, que se encargan de la comprensión y de la producción del lenguaje respectivamente (missing reference). Siguiendo este ejemplo, parece lógico hacer que nuestros sujetos estén formados por dos redes diferentes y desconectadas. Una de estas redes, el &lt;em&gt;encoder&lt;/em&gt; se encargará de producir el lenguaje mientras que el &lt;em&gt;decoder&lt;/em&gt; tratará de comprenderlo. En caso de que A quiera transmitir una idea a B, será el &lt;em&gt;encoder&lt;/em&gt; de A el responsable de transformar esta idea a un lenguaje común y el &lt;em&gt;decoder&lt;/em&gt; de B lo interpretará.&lt;/p&gt;

&lt;!-- Una figura de la estructura aquí --&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;/ol&gt;
&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;En realidad el área de Wernicke y el área de Broca están conectadas por el fascículo arqueado (missing reference). &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html">La pregunta que encabeza este post es recurrente en todos los círculos de la Inteligencia Artificial. Aquellos que trabajan en NLP (procesamiento de lenguaje natural por sus siglas en inglés) buscan concebir sistemas que sean capaces de entender (procesar) lenguaje producido por seres humanos y tomar acciones acordes. GPT-3 es un ejemplo de esto, el cometido de este modelo tan solo es predecir (muy acertadamente) la palabra más probable que seguirá una secuencia de texto (missing reference). Sin embargo, según cómo ha sido entrenado, en ningún caso se puede defender que el modelo posea una comprensión profunda de las palabras que está produciendo ni que tenga un objetivo en particular al expresarlas. Si se me permite mi opinión, creo que el salto que nos queda por delante hasta cubrir este último punto es todavía enorme y no vendrá en los próximos años. Al fin y al cabo, todavía no entendemos cómo funciona la mente humana.</summary></entry></feed>