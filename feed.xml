<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://www.javiergamazo.com//blog/feed.xml" rel="self" type="application/atom+xml" /><link href="https://www.javiergamazo.com//blog/" rel="alternate" type="text/html" /><updated>2020-12-20T14:38:18+00:00</updated><id>https://www.javiergamazo.com//blog/feed.xml</id><title type="html">DidYouKnow</title><subtitle>The place where I talk about anything</subtitle><entry><title type="html">¿Puede una IA inventar un idioma?</title><link href="https://www.javiergamazo.com//blog/jekyll/update/2020/11/07/es_draft.html" rel="alternate" type="text/html" title="¿Puede una IA inventar un idioma?" /><published>2020-11-07T18:39:02+00:00</published><updated>2020-11-07T18:39:02+00:00</updated><id>https://www.javiergamazo.com//blog/jekyll/update/2020/11/07/es_draft</id><content type="html" xml:base="https://www.javiergamazo.com//blog/jekyll/update/2020/11/07/es_draft.html">&lt;p&gt;La pregunta que encabeza este post es recurrente en todos los círculos de la Inteligencia Artificial. Aquellos que trabajan en NLP (procesamiento de lenguaje natural por sus siglas en inglés) buscan concebir sistemas que sean capaces de entender (procesar) lenguaje producido por seres humanos y tomar acciones acordes. GPT-3 es un ejemplo de esto, el cometido de este modelo tan solo es predecir (muy acertadamente) la palabra más probable que seguirá una secuencia de texto (missing reference). Sin embargo, según cómo ha sido entrenado, en ningún caso se puede defender que el modelo posea una comprensión profunda de las palabras que está produciendo ni que tenga un objetivo en particular al expresarlas. Si se me permite mi opinión, creo que el salto que nos queda por delante hasta cubrir este último punto es todavía enorme y no vendrá en los próximos años. Al fin y al cabo, todavía no entendemos cómo funciona la mente humana.&lt;/p&gt;

&lt;p&gt;Si atendemos a la definición de “idioma” en el Diccionario, ésta es “Lengua de un pueblo o nación, o común a varios” (missing reference), mientras que una de las acepciones de “lengua” es “Sistema de comunicación verbal propio de una comunidad humana y que cuenta generalmente con escritura” (missing reference). Cuando hablemos de “idioma” en este post, por lo tanto, nos estaremos refiriendo a un lenguaje común que compartan varios sistemas a través del cual puedan llegar a entenderse y transmitir ideas. No obstante, estas ideas vendrán predefinidas por un agente externo a la IA. Un ejemplo básico podría ser transmitir un número aleatorio de7 0 a 9 del sistema A al B en un lenguaje común, que el B lo procesara, calculara su doble, lo devolviera a A y éste diera con la respuesta correcta. En este post intentaremos sentar las bases de un proyecto que cumpla todos esos requisitos y una condición más: que el idioma que compartan ambos sistemas sea similar al del droide R2-D2 de Star Wars.&lt;/p&gt;

&lt;h3 id=&quot;dos-no-hablan-si-uno-no-quiere&quot;&gt;Dos no hablan si uno no quiere&lt;/h3&gt;

&lt;p&gt;Efectivamente, para que exista comunicación debe haber al menos dos sistemas: un emisor de información (transmisor) y otro receptor de la misma. Siguiendo la Teoría de la Comunicación de Claude E. Shannon (missing reference), es necesario además una fuente de información, un canal, un mensaje, un destinatario y un elemento de ruido. Si bien la definición precisa de estos componentes se deja a discreción del lector, es de capital importancia para este proyecto distinguir entre &lt;span style=&quot;color:blue&quot;&gt;fuente de información&lt;/span&gt; y &lt;span style=&quot;color:red&quot;&gt;transmisor&lt;/span&gt;, y &lt;span style=&quot;color:blue&quot;&gt;destinatario&lt;/span&gt; y &lt;span style=&quot;color:red&quot;&gt;receptor&lt;/span&gt;: cuando hablamos de transmisor nos referimos al sistema técnico encargado de &lt;em&gt;codificar&lt;/em&gt; la fuente de información a un conjunto de señales aptas para el canal (y viceversa para el receptor, que la &lt;em&gt;decodifica&lt;/em&gt; para que el destinatario pueda utilizar la información). Aplicado a la comunicación verbal entre dos personas A y B, la fuente de información será la idea de A, cuyo cerebro se encargará de codificar en forma de palabras (mensaje) que se enviarán por el aire (canal) hasta llegar a B. El cerebro de B decodificará las palabras y generará una idea, que en el mejor de los casos será igual a la idea del cerebro de A.
&lt;!-- Habría que poner una foto aquí de la teoría de información --&gt;&lt;/p&gt;

&lt;p&gt;Transformemos ahora esta teoría al campo de la IA. Como sabemos, las redes neuronales son tremendamente eficaces a la hora de generar representaciones a partir de datos, por lo que podríamos enfrentar dos de ellas (sujetos A y B) y hacerlas compartir mensajes. A codificaría el mensaje y B lo… ¿decodificaría? ¿Y qué pasaría si B quisiera transmitir una idea a A? Para encontrar la solución a esta pregunta podemos fijarnos en el sistema más eficiente que conocemos a la hora de producir y procesar lenguaje: el cerebro. Este órgano se encarga de ambas funciones simultáneamente (¿o es que no puedes escuchar música y hablar a la vez?), y eso se debe a que el flujo de información transcurre por zonas separadas&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;. Estas dos zonas son el área de Wernicke y el área de Broca, que se encargan de la comprensión y de la producción del lenguaje respectivamente (missing reference). Siguiendo este ejemplo, parece lógico hacer que nuestros sujetos estén formados por dos redes diferentes y desconectadas. Una de estas redes, el &lt;em&gt;encoder&lt;/em&gt; se encargará de producir el lenguaje mientras que el &lt;em&gt;decoder&lt;/em&gt; tratará de comprenderlo. En caso de que A quiera transmitir una idea a B, será el &lt;em&gt;encoder&lt;/em&gt; de A el responsable de transformar esta idea a un lenguaje común y el &lt;em&gt;decoder&lt;/em&gt; de B lo interpretará.&lt;/p&gt;

&lt;!-- Una figura de la estructura aquí --&gt;

&lt;h3 id=&quot;hablemos-tan-claro-como-r2-d2&quot;&gt;Hablemos tan claro como R2-D2&lt;/h3&gt;

&lt;p&gt;Describiré en primer lugar la forma de comunicarse de R2-D2 ara aquellos que la desconozcan. Se trata de una serie de pitidos, silbidos y otros sonidos aglutinados para formar algo que se asemeja a frases (missing reference). En YouTube hay &lt;a href=&quot;https://www.youtube.com/watch?v=2-BKjnAgNgY&quot; target=&quot;_blank&quot;&gt;infinidad&lt;/a&gt; de vídeos mostrando estos sonidos (se abre en otra pestaña). Intentaremos hacer que las redes neuronales imiten este lenguaje a la hora de hablar, forzando que la representación de la idea por parte del &lt;em&gt;encoder&lt;/em&gt; sea también una serie de pitidos. Sin embargo, forzar este tipo de representación no es trivial por dos motivos: en primer lugar, el lenguaje debe ser creado espontáneamente a través de la conversación entre las redes, no debe existir ningún tipo de interacción humana en este proceso. En segundo lugar, debemos definir a qué nos referimos con “representación” en este contexto puesto que el lenguaje es muy variado. Abordaremos primero la segunda cuestión, lo que nos llevará inexorablemente hasta la solución de la primera.&lt;/p&gt;

&lt;p&gt;Un sonido puede ser representado de tres formas diferentes en función de lo que busquemos conocer acerca del mismo:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Representación temporal: muestra la intensidad del sonido en función del tiempo.&lt;/li&gt;
  &lt;li&gt;Representación en frecuencias: explicado muy brevemente, todo sonido, por el hecho de ser una onda en función del tiempo, puede ser descompuesto en ondas más básicas con diferentes frecuencias. El método con el que pasamos de una onda en el dominio temporal a una onda en el dominio de frecuencias recibe el nombre de &lt;em&gt;transformada de Fourier&lt;/em&gt;. La representación en frecuencias contiene información de lo importante (amplitud) que es cada frecuencia para dar lugar al sonido subyacente.&lt;/li&gt;
  &lt;li&gt;Representación en forma de espectrograma: las dos representaciones anteriores tienen dos dimensiones, i.e. amplitud en función del tiempo o amplitud de cada frecuencia. Sin embargo, podemos unir ambas para dar lugar a una representación tridimensional: tiempo, amplitud y frecuencia. Un espectrograma muestra la evolución de la frecuencia y de la intensidad en el tiempo. Típicamente, la intensidad se define por el color, mientras que las otras dos dimensiones toman los ejes de abscisas (tiempo) y ordenadas (frecuencia). A diferencia de en los casos anteriores, un espectrograma puede ser guardado en forma de imagen ya que la informaciónm relevante está codificada tanto en el color de los píxeles como en su posición.&lt;/li&gt;
&lt;/ul&gt;

&lt;!-- Foto de las tres representaciones --&gt;

&lt;p&gt;Se ha demostrado que las redes neuronales operan bien con datos tabulados y especialmente bien con imágenes (missing reference)(missing reference), así que parece lógico utilizar el espectograma para esta tarea. En general, para trabajar con imágenes se utilizan redes neuronales convolucionales. Explicar en detalle cómo funcionan este tipo de redes daría para otro artículo, por lo que se deja al lector interesado el familiarizarse con este tipo de arquitecturas, ya que existen multitud de recursos disponibles ((missing reference), por ejemplo). Tan solo diré aquí que con una red de capas convolucionales podemos obtener una representación en varias dimensiones de los datos de entrada (una imagen). Es decir, podemos conseguir la traducción de un número cualquiera en una imagen, y esta traducción puede ser aprendida para una tarea concreta. De esta forma, el diagrama anterior adquiere la siguiente estructura:&lt;/p&gt;

&lt;!-- Una figura de la estructura aquí con un espectrograma en medio --&gt;

&lt;p&gt;Para hacer que un sistema de redes neuronales se comporte como queremos hay que especificar una cantidad a minimizar. A esta cantidad se le llama &lt;em&gt;loss&lt;/em&gt;, y en muchos casos es una función que depende de la salida de la red y de los datos originales &lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;. Aplicado a nuestro problema, podemos definir inmediatamente una cantidad que el sistema debe minimizar: queremos que B interprete la misma idea que está intentando de transmitir A. Concretamente, queremos que si A transmite el número 5, la predicción de B sea el número 5.&lt;/p&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;/ol&gt;
&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;En realidad el área de Wernicke y el área de Broca están conectadas por el fascículo arqueado (missing reference). &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Esto aplica en modelos supervisados, en los que conocemos el valor que debería predecir el modelo para cada valor de entrada. Existen otros tipos de algoritmos (no supervisados, por ejemplo), en los que esto no se cumple y la función de &lt;em&gt;loss&lt;/em&gt; adquiere otras formas. &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html">La pregunta que encabeza este post es recurrente en todos los círculos de la Inteligencia Artificial. Aquellos que trabajan en NLP (procesamiento de lenguaje natural por sus siglas en inglés) buscan concebir sistemas que sean capaces de entender (procesar) lenguaje producido por seres humanos y tomar acciones acordes. GPT-3 es un ejemplo de esto, el cometido de este modelo tan solo es predecir (muy acertadamente) la palabra más probable que seguirá una secuencia de texto (missing reference). Sin embargo, según cómo ha sido entrenado, en ningún caso se puede defender que el modelo posea una comprensión profunda de las palabras que está produciendo ni que tenga un objetivo en particular al expresarlas. Si se me permite mi opinión, creo que el salto que nos queda por delante hasta cubrir este último punto es todavía enorme y no vendrá en los próximos años. Al fin y al cabo, todavía no entendemos cómo funciona la mente humana.</summary></entry></feed>